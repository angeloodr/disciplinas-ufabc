import pandas as pd
import networkx as nx
import unicodedata
import requests
from io import StringIO
from node2vec import Node2Vec
import numpy as np

# ‚úÖ Normaliza uma string removendo acentos e espa√ßos extras
def normalize_str(s: str) -> str:
    return (
        unicodedata.normalize('NFKD', s)
        .encode('ASCII', 'ignore')
        .decode('utf-8')
        .strip()
    )

# ‚úÖ Vers√£o espec√≠fica para nomes de disciplinas (j√° normaliza e coloca lowercase)
def normalizar_nome(nome: str) -> str:
    return normalize_str(nome).lower()

# ‚úÖ Baixa o cat√°logo da UFABC direto do GitHub
def carregar_catalogo():
    url = "https://raw.githubusercontent.com/angeloodr/disciplinas-ufabc/main/catalogo_disciplinas_graduacao_2024_2025.tsv"
    print("üîÑ Baixando cat√°logo de disciplinas...")
    resp = requests.get(url)
    resp.raise_for_status()
    df = pd.read_csv(StringIO(resp.text), sep='\t')

    # Normaliza os nomes das colunas
    df.columns = [
        normalize_str(col).upper().replace(' ', '_')
        for col in df.columns
    ]
    print("‚úÖ Download bem-sucedido!")
    print("üìù Colunas dispon√≠veis:", df.columns.tolist())
    return df

# ‚úÖ Constr√≥i grafo com arestas de pr√©-requisito com base na coluna RECOMENDACAO
def construir_grafo(df: pd.DataFrame) -> nx.DiGraph:
    print("üìå Construindo grafo de pr√©-requisitos...")
    G = nx.DiGraph()
    total_arestas = 0

    # Cria um dicion√°rio de nome normalizado ‚Üí sigla
    mapping = {
        normalizar_nome(row['DISCIPLINA']): row['SIGLA']
        for _, row in df.iterrows()
        if pd.notna(row['SIGLA'])
    }

    # Adiciona todos os n√≥s com metadados
    for _, row in df.iterrows():
        sigla = row['SIGLA']
        nome = row['DISCIPLINA']
        if pd.isna(sigla): 
            continue
        G.add_node(sigla, nome=nome)

    # Adiciona as arestas baseadas nas recomenda√ß√µes
    for _, row in df.iterrows():
        curso = row['SIGLA']
        if pd.isna(curso):
            continue

        recs = row.get('RECOMENDACAO', '')
        if pd.isna(recs) or not isinstance(recs, str):
            continue

        for rec in recs.split(';'):
            rec = rec.strip()
            if not rec:
                continue
            rec_norm = normalizar_nome(rec)
            if rec_norm in mapping:
                prereq = mapping[rec_norm]
                if not G.has_edge(prereq, curso):
                    G.add_edge(prereq, curso, tipo='pre_requisito')
                    total_arestas += 1

    print(f"‚úÖ Grafo criado com {G.number_of_nodes()} n√≥s e {total_arestas} arestas.")
    return G

# ‚úÖ Remove ciclos do grafo para que seja um DAG (necess√°rio para c√°lculo de profundidade)
def remover_ciclos(G: nx.DiGraph) -> nx.DiGraph:
    print("üîÅ Removendo ciclos (modo eficiente)...")
    G_copy = G.copy()
    removidos = 0
    try:
        while True:
            ciclo = nx.find_cycle(G_copy, orientation='original')
            if ciclo:
                # Remove a primeira aresta do ciclo
                u, v, _ = ciclo[0]
                G_copy.remove_edge(u, v)
                removidos += 1
    except nx.NetworkXNoCycle:
        pass  # N√£o h√° mais ciclos

    print(f"‚úÖ Ciclos removidos: {removidos}")
    return G_copy

# ‚úÖ Gera embeddings estruturais com Node2Vec
def gerar_embeddings_node2vec(G: nx.DiGraph, dimensions=64, walk_length=10, num_walks=50, workers=1):
    print("üîÑ Gerando embeddings estruturais (Node2Vec)...")
    node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=workers)
    model = node2vec.fit(window=5, min_count=1, batch_words=4)
    embeddings = {node: model.wv[node] for node in G.nodes()}
    print("‚úÖ Embeddings gerados!")
    return embeddings

# ‚úÖ Calcula profundidade de cada n√≥ no grafo (camada curricular)
def calcular_profundidade(G: nx.DiGraph):
    print("üìè Calculando profundidade no grafo (DAG)...")
    profundidades = {}
    for node in nx.topological_sort(G):
        preds = list(G.predecessors(node))
        if not preds:
            profundidades[node] = 0
        else:
            profundidades[node] = max(profundidades[p] for p in preds) + 1
    print("‚úÖ Profundidade calculada!")
    return profundidades

# ‚úÖ Salva os embeddings em CSV
def salvar_embeddings_csv(embeddings, caminho="embeddings_node2vec.csv"):
    df = pd.DataFrame.from_dict(embeddings, orient='index')
    df.index.name = 'DISCIPLINA'
    df.to_csv(caminho)
    print(f"üíæ Embeddings salvos em: {caminho}")

# ‚úÖ Fluxo principal
if __name__ == "__main__":
    # Etapa 1 - Carregar cat√°logo
    df = carregar_catalogo()

    # Etapa 2 - Construir grafo
    grafo = construir_grafo(df)
    nx.write_graphml(grafo, "grafo_pre_requisitos.graphml")
    print("üìÅ Arquivo salvo: grafo_pre_requisitos.graphml")

    # Etapa 3 - Gerar embeddings estruturais
    embeddings = gerar_embeddings_node2vec(grafo)
    salvar_embeddings_csv(embeddings)

    # Etapa 4 - Remover ciclos e calcular profundidade
    grafo_sem_ciclos = remover_ciclos(grafo)
    profundidades = calcular_profundidade(grafo_sem_ciclos)

    # Etapa 5 - Salvar profundidades em TXT
    with open("profundidade_nos.txt", "w") as f:
        for node, prof in profundidades.items():
            f.write(f"{node}: {prof}\n")
    print("üìÅ Profundidades salvas em: profundidade_nos.txt")
